{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.3\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.2\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : GCC 7.2.0\n",
      "system     : Linux\n",
      "release    : 4.13.0-36-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 8e9ff9c5eeff2b1d1c74d1838ad5bd4a507463cc\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'java', 'c++', 'android', 'php', 'ios', 'c#', 'javascript', 'python', 'jquery', 'html'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "\n",
    "        def sigmoid(x):\n",
    "            if x < 0:\n",
    "                a = np.exp(x) \n",
    "                return a / (1 + a) \n",
    "            else:\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def log(x):\n",
    "            if x < tolerance:\n",
    "                x = tolerance\n",
    "            return np.log(x)\n",
    "\n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                #if n == 15: break\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = sigmoid(z)\n",
    "                    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss +=  -(y * log(sigma) + (1 - y) * log(1 - sigma))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae79754371e4026b4edd8daef71312f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7784967828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.85\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. **19.74**\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "\n",
    "        def sigmoid(x):\n",
    "            if x < 0:\n",
    "                a = np.exp(x) \n",
    "                return a / (1 + a) \n",
    "            else:\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def log(x):\n",
    "            if x < tolerance:\n",
    "                x = tolerance\n",
    "            return np.log(x)\n",
    "\n",
    "        self._loss = []\n",
    "        predict = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predict_tags = set()\n",
    "                \n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = sigmoid(z)\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss +=  -(y * log(sigma) + (1 - y) * log(1 - sigma))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma > 0.9:\n",
    "                            predict_tags.add(tag)\n",
    "                if n >= top_n_train:\n",
    "                    prob = len(tags & predict_tags) / len(tags | predict_tags)\n",
    "                    predict.append(prob)\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.mean(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3dbc539e4142ceb00619a225fc2907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. **0.59**\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda = 0.01):\n",
    "\n",
    "        def sigmoid(x):\n",
    "            if x < 0:\n",
    "                a = np.exp(x) \n",
    "                return a / (1 + a) \n",
    "            else:\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def log(x):\n",
    "            if x < tolerance:\n",
    "                x = tolerance\n",
    "            return np.log(x)\n",
    "\n",
    "        self._loss = []\n",
    "        predict = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predict_tags = set()\n",
    "                \n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                        \n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = sigmoid(z)\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss +=  -(y * log(sigma) + (1 - y) * log(1 - sigma))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        first_word = set()\n",
    "                        for word in sentence: #np.unique(sentence):\n",
    "                            if word in first_word:\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate * dLdw\n",
    "                            else:\n",
    "                                first_word.add(word)\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate*(dLdw - lmbda * self._w[tag][self._vocab[word]])\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma >= 0.9:\n",
    "                            predict_tags.add(tag)\n",
    "                if n >= top_n_train:\n",
    "                    if n >100000 and n < 100010:\n",
    "                        print(tags,predict_tags)\n",
    "                    prob = len(tags & predict_tags) / len(tags | predict_tags)\n",
    "                    predict.append(prob)\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.mean(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7230ead0284935b887fab5ae52a666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android'} {'android'}\n",
      "{'android'} {'java', 'android'}\n",
      "{'php', 'html'} {'javascript', 'jquery', 'html'}\n",
      "{'android'} {'jquery', 'c#'}\n",
      "{'ios'} {'javascript', 'ios'}\n",
      "{'java'} {'java'}\n",
      "{'php'} {'python'}\n",
      "{'android'} {'android'}\n",
      "{'python'} {'python'}\n",
      "\n",
      "0.54\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7792981eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. **0.52**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda = 0.0002,\n",
    "                     gamma=0.1):\n",
    "\n",
    "        def sigmoid(x):\n",
    "            if x < 0:\n",
    "                a = np.exp(x) \n",
    "                return a / (1 + a) \n",
    "            else:\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def log(x):\n",
    "            if x < tolerance:\n",
    "                x = tolerance\n",
    "            return np.log(x)\n",
    "\n",
    "        self._loss = []\n",
    "        predict = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predict_tags = set()\n",
    "                \n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                        \n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = sigmoid(z)\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss +=  -(y * log(sigma) + (1 - y) * log(1 - sigma))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        first_word = set()\n",
    "                        for word in sentence: #np.unique(sentence):\n",
    "                            if word in first_word:\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate * dLdw\n",
    "                            else:\n",
    "                                first_word.add(word)\n",
    "                                _w = self._w[tag][self._vocab[word]]\n",
    "                                w_reg = lmbda * (2 * gamma * _w + (1-gamma)*np.sign(_w))\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate*(dLdw - w_reg)\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma >= 0.9:\n",
    "                            predict_tags.add(tag)\n",
    "                if n >= top_n_train:\n",
    "                    if n >100000 and n < 100010:\n",
    "                        print(tags,predict_tags)\n",
    "                    prob = len(tags & predict_tags) / len(tags | predict_tags)\n",
    "                    predict.append(prob)\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.mean(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f435f0fae3874e1abe655a03c966d5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android'} {'android'}\n",
      "{'android'} {'android'}\n",
      "{'php', 'html'} {'html'}\n",
      "{'android'} {'jquery'}\n",
      "{'ios'} {'javascript', 'ios'}\n",
      "{'java'} {'java'}\n",
      "{'php'} {'python'}\n",
      "{'android'} {'android'}\n",
      "{'python'} {'python'}\n",
      "\n",
      "0.58\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f77936e0710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. **0.59**\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java : println, java, dx, hibernate, spring\n",
      "c++ : avrf, c++, std, cout, const\n",
      "android : android, activity, imgsrv, 29297, 0x0\n",
      "php : php, _post, echo, x5c, 125\n",
      "ios : ios, nsstring, xcode, nil, nslog\n",
      "c# : xsl, writeline, net, binding, foreach\n",
      "javascript : javascript, x20, 125, 3, x30\n",
      "python : python, def, 00, py, django\n",
      "jquery : jquery, ready, ajax, val, li\n",
      "html : br, amp, span, lt, html\n"
     ]
    }
   ],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. **c# **\n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda = 0.0002,\n",
    "                     gamma=0.1,\n",
    "                     update_vocab = True):\n",
    "\n",
    "        def sigmoid(x):\n",
    "            if x < 0:\n",
    "                a = np.exp(x) \n",
    "                return a / (1 + a) \n",
    "            else:\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def log(x):\n",
    "            if x < tolerance:\n",
    "                x = tolerance\n",
    "            return np.log(x)\n",
    "\n",
    "        self._loss = []\n",
    "        self._all_words = []\n",
    "        predict = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                \n",
    "                if n < top_n_train:\n",
    "                    self._all_words.extend(sentence)\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predict_tags = set()\n",
    "                \n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab and update_vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        if word in self._vocab:\n",
    "                            z += self._w[tag][self._vocab[word]]\n",
    "                        \n",
    "                        \n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = sigmoid(z)\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss +=  -(y * log(sigma) + (1 - y) * log(1 - sigma))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        first_word = set()\n",
    "                        for word in sentence: #np.unique(sentence):\n",
    "                            if word not in self._vocab:\n",
    "                                continue\n",
    "                            if word in first_word:\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate * dLdw\n",
    "                            else:\n",
    "                                first_word.add(word)\n",
    "                                _w = self._w[tag][self._vocab[word]]\n",
    "                                w_reg = lmbda * (2 * gamma * _w + (1-gamma)*np.sign(_w))\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate*(dLdw - w_reg)\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma >= 0.9:\n",
    "                            predict_tags.add(tag)\n",
    "                if n >= top_n_train:\n",
    "                    if n >100000 and n < 100010:\n",
    "                        print(tags,predict_tags)\n",
    "                    prob = len(tags & predict_tags) / len(tags | predict_tags)\n",
    "                    predict.append(prob)\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.mean(predict)\n",
    "    \n",
    "    def filter_vocab(self, n=10000):\n",
    "        bag_of_words = Counter(self._all_words).most_common(n)\n",
    "        newvocab = dict((el, self._vocab[el]) for el, _ in bag_of_words)\n",
    "        self._vocab = newvocab\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7203cb2a2e7a499ead21267a7e8cb342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android'} {'android'}\n",
      "{'android'} {'android'}\n",
      "{'php', 'html'} {'html'}\n",
      "{'android'} {'jquery'}\n",
      "{'ios'} {'javascript', 'ios'}\n",
      "{'java'} {'java'}\n",
      "{'php'} {'python'}\n",
      "{'android'} {'android'}\n",
      "{'python'} {'python'}\n",
      "\n",
      "0.58\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f774274d400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a0ddf1f22a4b16b957831d515f1bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android'} {'android'}\n",
      "{'android'} {'android', 'php'}\n",
      "{'php', 'html'} {'javascript'}\n",
      "{'android'} {'java'}\n",
      "{'ios'} {'ios'}\n",
      "{'java'} {'java'}\n",
      "{'php'} {'php', 'python'}\n",
      "{'android'} {'android'}\n",
      "{'python'} {'python'}\n",
      "\n",
      "0.69\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f77439f7da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. **0.68**\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda = 0.0002,\n",
    "                     gamma=0.1,\n",
    "                     update_vocab = True):\n",
    "\n",
    "        def sigmoid(x):\n",
    "            if x < 0:\n",
    "                a = np.exp(x) \n",
    "                return a / (1 + a) \n",
    "            else:\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def log(x):\n",
    "            if x < tolerance:\n",
    "                x = tolerance\n",
    "            return np.log(x)\n",
    "\n",
    "        self._loss = []\n",
    "        self._all_words = []\n",
    "        predict = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                \n",
    "                if n < top_n_train:\n",
    "                    self._all_words.extend(sentence)\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predict_tags = set()\n",
    "                \n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab and update_vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        if word in self._vocab:\n",
    "                            z += self._w[tag][self._vocab[word]]\n",
    "                        \n",
    "                        \n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = sigmoid(z)\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss +=  -(y * log(sigma) + (1 - y) * log(1 - sigma))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        first_word = set()\n",
    "                        for word in sentence: #np.unique(sentence):\n",
    "                            if word not in self._vocab:\n",
    "                                continue\n",
    "                            if word in first_word:\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate * dLdw\n",
    "                            else:\n",
    "                                first_word.add(word)\n",
    "                                _w = self._w[tag][self._vocab[word]]\n",
    "                                w_reg = lmbda * (2 * gamma * _w + (1-gamma)*np.sign(_w))\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate*(dLdw - w_reg)\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma >= 0.9:\n",
    "                            predict_tags.add(tag)\n",
    "                if n >= top_n_train:\n",
    "                    if n >100000 and n < 100010:\n",
    "                        print(tags,predict_tags)\n",
    "                    prob = len(tags & predict_tags) / len(tags | predict_tags)\n",
    "                    predict.append(prob)\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.mean(predict)\n",
    "    \n",
    "    def filter_vocab(self, n=10000):\n",
    "        bag_of_words = Counter(self._all_words).most_common(n)\n",
    "        newvocab = dict((el, self._vocab[el]) for el, _ in bag_of_words)\n",
    "        self._vocab = newvocab\n",
    "\n",
    "    def predict_proba(self, sentence):\n",
    "        def sigmoid(x):\n",
    "            if x < 0:\n",
    "                a = np.exp(x) \n",
    "                return a / (1 + a) \n",
    "            else:\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        predict_tags = {}\n",
    "        for tag in self._tags:\n",
    "            z = self._b[tag]\n",
    "            for word in sentence.split(' '):\n",
    "                if word in self._vocab:\n",
    "                    z += self._w[tag][self._vocab[word]]\n",
    "            sigma = sigmoid(z)\n",
    "            predict_tags[tag] = sigma\n",
    "        return predict_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5c15bbbad7440ea97dfecbbd8c2b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android'} {'android'}\n",
      "{'android'} {'android'}\n",
      "{'php', 'html'} {'html'}\n",
      "{'android'} {'jquery'}\n",
      "{'ios'} {'javascript', 'ios'}\n",
      "{'java'} {'java'}\n",
      "{'php'} {'python'}\n",
      "{'android'} {'android'}\n",
      "{'python'} {'python'}\n",
      "\n",
      "0.58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c52f0e66ab4bd2a74b9b2252db850c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android'} {'android'}\n",
      "{'android'} {'android', 'php'}\n",
      "{'php', 'html'} {'javascript'}\n",
      "{'android'} {'java'}\n",
      "{'ios'} {'ios'}\n",
      "{'java'} {'java'}\n",
      "{'php'} {'php', 'python'}\n",
      "{'android'} {'android'}\n",
      "{'python'} {'python'}\n",
      "\n",
      "0.69\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ios', 0.9999999999999996),\n",
       " ('php', 0.9999956114667254),\n",
       " ('android', 0.7045104239346488),\n",
       " ('javascript', 1.8773488463219853e-17),\n",
       " ('java', 1.1516634214136752e-22),\n",
       " ('c++', 2.0715317574571625e-28),\n",
       " ('html', 5.517708407065779e-31),\n",
       " ('c#', 5.504978233121361e-34),\n",
       " ('python', 2.8318091595203854e-34),\n",
       " ('jquery', 8.417015392512754e-48)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'android': -5.52515347923298,\n",
       " 'c#': -6.0669082829929994,\n",
       " 'c++': -8.888268541406788,\n",
       " 'html': -13.31390854118229,\n",
       " 'ios': -5.289948588494552,\n",
       " 'java': -4.922342806642927,\n",
       " 'javascript': -8.826707887108597,\n",
       " 'jquery': -20.45194308660567,\n",
       " 'php': -9.044469076237453,\n",
       " 'python': -8.52456664246456}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. **ios**\n",
    "3. **php**\n",
    "4. java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
